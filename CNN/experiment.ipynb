{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 读取数据\n",
    "- 分别构建训练集和测试集（验证集）\n",
    "- DataLoader 来迭代取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "input_size = 28     # 图像尺寸28*28\n",
    "num_classes = 10    # 标签种类\n",
    "num_epochs = 3      # 训练迭代次数\n",
    "batch_size = 64     # 64张/批次\n",
    "\n",
    "# 训练集\n",
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "# 测试集\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# 构建 batch 数据\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 卷积网络模块构建\n",
    "- 一般卷积层，ReLU层，池化层\n",
    "- 卷积最后结果还是一个特征图，需要把图转换成向量才能做分类或者回归任务"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(         # 输入大小 (1, 28, 28)\n",
    "            nn.Conv2d(in_channels=1,        # 灰度图\n",
    "                      out_channels=16,      # 特征图个数\n",
    "                      kernel_size=5,        # 卷积核大小\n",
    "                      stride=1,             # 步长\n",
    "                      padding=2             # 如果希望卷积后尺寸跟原来一样，\n",
    "                                            # 需要设置 padding=(kernel_size - 1)/2 if stride=1\n",
    "                      ),                    # 输出特征图为 (16, 28, 28)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),    # 池化 (2*2)，输出结果为 (16, 14, 14)\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Sequential(         # 输入大小 (16, 14, 14)\n",
    "            nn.Conv2d(in_channels=16,\n",
    "                      out_channels=32,\n",
    "                      kernel_size=5,\n",
    "                      stride=1,\n",
    "                      padding=2),           # 输出 (32, 14, 14)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)     # 输出 (32, 7, 7)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(\n",
    "            in_features=32*7*7,\n",
    "            out_features=10)                # 全连接层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(x.size(0), -1)           # flatten 操作，结果为 (batch_size, 32*7*7)\n",
    "        output = self.out(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 准确率作为评估标准"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    pred = torch.max(predictions.data, 1)[1]\n",
    "    rights = pred.eq(labels.data.view_as(pred)).sum()\n",
    "    return rights, len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 训练网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前 epoch: 0 [0/60000 (0%)]\t损失: 2.310593\t训练集准确率: 6.25%\t测试集准确率: 11.81%\n",
      "当前 epoch: 0 [6400/60000 (11%)]\t损失: 0.193468\t训练集准确率: 75.08%\t测试集准确率: 91.27%\n",
      "当前 epoch: 0 [12800/60000 (21%)]\t损失: 0.196862\t训练集准确率: 83.62%\t测试集准确率: 94.73%\n",
      "当前 epoch: 0 [19200/60000 (32%)]\t损失: 0.033648\t训练集准确率: 87.31%\t测试集准确率: 94.44%\n",
      "当前 epoch: 0 [25600/60000 (43%)]\t损失: 0.081400\t训练集准确率: 89.48%\t测试集准确率: 97.00%\n",
      "当前 epoch: 0 [32000/60000 (53%)]\t损失: 0.127010\t训练集准确率: 90.92%\t测试集准确率: 97.22%\n",
      "当前 epoch: 0 [38400/60000 (64%)]\t损失: 0.043472\t训练集准确率: 91.85%\t测试集准确率: 97.77%\n",
      "当前 epoch: 0 [44800/60000 (75%)]\t损失: 0.038948\t训练集准确率: 92.63%\t测试集准确率: 97.92%\n",
      "当前 epoch: 0 [51200/60000 (85%)]\t损失: 0.022165\t训练集准确率: 93.28%\t测试集准确率: 97.96%\n",
      "当前 epoch: 0 [57600/60000 (96%)]\t损失: 0.044342\t训练集准确率: 93.80%\t测试集准确率: 98.00%\n",
      "当前 epoch: 1 [0/60000 (0%)]\t损失: 0.296286\t训练集准确率: 92.19%\t测试集准确率: 98.21%\n",
      "当前 epoch: 1 [6400/60000 (11%)]\t损失: 0.089358\t训练集准确率: 98.08%\t测试集准确率: 98.24%\n",
      "当前 epoch: 1 [12800/60000 (21%)]\t损失: 0.024019\t训练集准确率: 98.13%\t测试集准确率: 98.38%\n",
      "当前 epoch: 1 [19200/60000 (32%)]\t损失: 0.053187\t训练集准确率: 98.19%\t测试集准确率: 98.64%\n",
      "当前 epoch: 1 [25600/60000 (43%)]\t损失: 0.061463\t训练集准确率: 98.19%\t测试集准确率: 98.62%\n",
      "当前 epoch: 1 [32000/60000 (53%)]\t损失: 0.160539\t训练集准确率: 98.21%\t测试集准确率: 98.61%\n",
      "当前 epoch: 1 [38400/60000 (64%)]\t损失: 0.097577\t训练集准确率: 98.24%\t测试集准确率: 98.75%\n",
      "当前 epoch: 1 [44800/60000 (75%)]\t损失: 0.112383\t训练集准确率: 98.23%\t测试集准确率: 98.46%\n",
      "当前 epoch: 1 [51200/60000 (85%)]\t损失: 0.005089\t训练集准确率: 98.23%\t测试集准确率: 98.53%\n",
      "当前 epoch: 1 [57600/60000 (96%)]\t损失: 0.029717\t训练集准确率: 98.28%\t测试集准确率: 98.42%\n",
      "当前 epoch: 2 [0/60000 (0%)]\t损失: 0.028693\t训练集准确率: 100.00%\t测试集准确率: 98.73%\n",
      "当前 epoch: 2 [6400/60000 (11%)]\t损失: 0.116600\t训练集准确率: 98.67%\t测试集准确率: 98.52%\n",
      "当前 epoch: 2 [12800/60000 (21%)]\t损失: 0.029254\t训练集准确率: 98.73%\t测试集准确率: 98.48%\n",
      "当前 epoch: 2 [19200/60000 (32%)]\t损失: 0.032077\t训练集准确率: 98.70%\t测试集准确率: 98.49%\n",
      "当前 epoch: 2 [25600/60000 (43%)]\t损失: 0.005555\t训练集准确率: 98.73%\t测试集准确率: 98.70%\n",
      "当前 epoch: 2 [32000/60000 (53%)]\t损失: 0.005870\t训练集准确率: 98.70%\t测试集准确率: 98.70%\n",
      "当前 epoch: 2 [38400/60000 (64%)]\t损失: 0.044494\t训练集准确率: 98.71%\t测试集准确率: 98.41%\n",
      "当前 epoch: 2 [44800/60000 (75%)]\t损失: 0.001431\t训练集准确率: 98.75%\t测试集准确率: 98.79%\n",
      "当前 epoch: 2 [51200/60000 (85%)]\t损失: 0.013948\t训练集准确率: 98.73%\t测试集准确率: 98.91%\n",
      "当前 epoch: 2 [57600/60000 (96%)]\t损失: 0.056772\t训练集准确率: 98.73%\t测试集准确率: 99.02%\n"
     ]
    }
   ],
   "source": [
    "# 实例化\n",
    "net = CNN()\n",
    "# 损失函数\n",
    "crossEntropy = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)  # 定义优化器，普通随机梯度下降算法\n",
    "\n",
    "# train\n",
    "for epoch in range(num_epochs):\n",
    "    # 当前 epoch 的结果保存下来\n",
    "    train_rights = []\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):   # 针对容器中的每一批进行循环\n",
    "        net.train()\n",
    "        output = net(data)\n",
    "        loss = crossEntropy(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        right = accuracy(output, target)\n",
    "        train_rights.append(right)\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            net.eval()\n",
    "            val_rights = []\n",
    "\n",
    "            for (data, target) in test_loader:\n",
    "                output = net(data)\n",
    "                right = accuracy(output, target)\n",
    "                val_rights.append(right)\n",
    "\n",
    "            # 准确率计算\n",
    "            train_r = (\n",
    "                sum([tup[0] for tup in train_rights]),\n",
    "                sum([tup[1] for tup in train_rights])\n",
    "            )\n",
    "            val_r = (\n",
    "                sum([tup[0] for tup in val_rights]),\n",
    "                sum([tup[1] for tup in val_rights])\n",
    "            )\n",
    "\n",
    "            print('当前 epoch: {} [{}/{} ({:.0f}%)]\\t损失: {:.6f}\\t训练集准确率: {:.2f}%\\t测试集准确率: {:.2f}%'.format(\n",
    "                epoch, batch_idx*batch_size, len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),\n",
    "                loss.data,\n",
    "                100. * train_r[0].numpy() / train_r[1],\n",
    "                100. * val_r[0].numpy() / val_r[1]\n",
    "            ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5be32f89c6aeef54ba20325ebcf82c76fcabdbf34d446974977f35021bb2136c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
